{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating EMDs based on motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motifs.config import PKG_DATA_PATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/Thinkpad/Documents/GitHub/VictorIA-Hugo/src/motifs_space/motifs/data')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete\n",
    "PKG_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the directory:\n",
      "hugo2neutral_para__merged.csv\n",
      "hugo_para__merged.csv\n",
      "neutral2hugo_para__merged.csv\n"
     ]
    }
   ],
   "source": [
    "# ['hugo2neu2hugo']\n",
    "\n",
    "path_hnh = PKG_DATA_PATH.joinpath(\"hugo2neu2hugo_merged/tokens\")\n",
    "files_hnh = [f for f in os.listdir(path_hnh) if os.path.isfile(os.path.join(path_hnh, f))]\n",
    "\n",
    "# Print the list of files\n",
    "print(\"Files in the directory:\")\n",
    "for file in files_hnh:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugo_para = pd.read_csv(f\"{path_hnh}/hugo_para__merged.csv\")\n",
    "hugo2neutral_para = pd.read_csv(f\"{path_hnh}/hugo2neutral_para__merged.csv\")\n",
    "neutral2hugo_para = pd.read_csv(f\"{path_hnh}/neutral2hugo_para__merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>morph</th>\n",
       "      <th>dep</th>\n",
       "      <th>n_lefts</th>\n",
       "      <th>n_rights</th>\n",
       "      <th>is_sent_start</th>\n",
       "      <th>motif</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Habitué</td>\n",
       "      <td>Habituer</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part</td>\n",
       "      <td>advcl</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PPAS</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo_para__merged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>à</td>\n",
       "      <td>à</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>à</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo_para__merged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>les</td>\n",
       "      <td>le</td>\n",
       "      <td>DET</td>\n",
       "      <td>Definite=Def|Gender=Fem|Number=Plur|PronType=Art</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>le</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo_para__merged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absences</td>\n",
       "      <td>absence</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Gender=Fem|Number=Plur</td>\n",
       "      <td>obl:arg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo_para__merged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo_para__merged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text     lemma    pos  \\\n",
       "0   Habitué  Habituer   VERB   \n",
       "1         à         à    ADP   \n",
       "2       les        le    DET   \n",
       "3  absences   absence   NOUN   \n",
       "4         ,         ,  PUNCT   \n",
       "\n",
       "                                              morph      dep  n_lefts  \\\n",
       "0  Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part    advcl        0   \n",
       "1                                               NaN     case        0   \n",
       "2  Definite=Def|Gender=Fem|Number=Plur|PronType=Art      det        0   \n",
       "3                            Gender=Fem|Number=Plur  obl:arg        2   \n",
       "4                                               NaN    punct        0   \n",
       "\n",
       "   n_rights  is_sent_start motif  sent_id                doc  \n",
       "0         2           True  PPAS        0  hugo_para__merged  \n",
       "1         0          False     à        0  hugo_para__merged  \n",
       "2         0          False    le        0  hugo_para__merged  \n",
       "3         0          False    NC        0  hugo_para__merged  \n",
       "4         0          False     ,        0  hugo_para__merged  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hugo_para.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>morph</th>\n",
       "      <th>dep</th>\n",
       "      <th>n_lefts</th>\n",
       "      <th>n_rights</th>\n",
       "      <th>is_sent_start</th>\n",
       "      <th>motif</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le</td>\n",
       "      <td>le</td>\n",
       "      <td>DET</td>\n",
       "      <td>Definite=Def|Gender=Masc|Number=Sing|PronType=Art</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>le</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo2neutral_para__merged</td>\n",
       "      <td>hugo2neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>devoir</td>\n",
       "      <td>devoir</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Gender=Masc|Number=Sing</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo2neutral_para__merged</td>\n",
       "      <td>hugo2neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>était</td>\n",
       "      <td>être</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbFo...</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>être</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo2neutral_para__merged</td>\n",
       "      <td>hugo2neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo2neutral_para__merged</td>\n",
       "      <td>hugo2neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nuire</td>\n",
       "      <td>nuire</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VerbForm=Inf</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>INF</td>\n",
       "      <td>0</td>\n",
       "      <td>hugo2neutral_para__merged</td>\n",
       "      <td>hugo2neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text   lemma   pos                                              morph  \\\n",
       "0      Le      le   DET  Definite=Def|Gender=Masc|Number=Sing|PronType=Art   \n",
       "1  devoir  devoir  NOUN                            Gender=Masc|Number=Sing   \n",
       "2   était    être  VERB  Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbFo...   \n",
       "3      de      de   ADP                                                NaN   \n",
       "4   nuire   nuire  VERB                                       VerbForm=Inf   \n",
       "\n",
       "     dep  n_lefts  n_rights  is_sent_start motif  sent_id  \\\n",
       "0    det        0         0           True    le        0   \n",
       "1  nsubj        1         0          False    NC        0   \n",
       "2   ROOT        1         2          False  être        0   \n",
       "3   mark        0         0          False    de        0   \n",
       "4  ccomp        1         2          False   INF        0   \n",
       "\n",
       "                         doc        author  \n",
       "0  hugo2neutral_para__merged  hugo2neutral  \n",
       "1  hugo2neutral_para__merged  hugo2neutral  \n",
       "2  hugo2neutral_para__merged  hugo2neutral  \n",
       "3  hugo2neutral_para__merged  hugo2neutral  \n",
       "4  hugo2neutral_para__merged  hugo2neutral  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in files_hnh:\n",
    "    s = str(path_hnh) + '\\\\' + file\n",
    "    df = pd.read_csv(s)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data_hnh = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "data_hnh['author'] = data_hnh['doc'].str.split('_para').str[0]\n",
    "data_hnh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hugo2neutral', 'hugo', 'neutral2hugo'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hnh.author.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the directory:\n",
      "colette2hugo_para_27.csv\n",
      "colette2hugo_para_28.csv\n",
      "colette2hugo_para_29.csv\n",
      "colette2hugo_para_30.csv\n",
      "colette2hugo_para_31.csv\n",
      "colette2hugo_para_32.csv\n",
      "colette_para_27.csv\n",
      "colette_para_28.csv\n",
      "colette_para_29.csv\n",
      "colette_para_30.csv\n",
      "colette_para_31.csv\n",
      "colette_para_32.csv\n",
      "daudet2hugo_para_10.csv\n",
      "daudet2hugo_para_11.csv\n",
      "daudet2hugo_para_12.csv\n",
      "daudet2hugo_para_13.csv\n",
      "daudet2hugo_para_40.csv\n",
      "daudet2hugo_para_8.csv\n",
      "daudet2hugo_para_9.csv\n",
      "daudet_para_10.csv\n",
      "daudet_para_11.csv\n",
      "daudet_para_12.csv\n",
      "daudet_para_13.csv\n",
      "daudet_para_40.csv\n",
      "daudet_para_8.csv\n",
      "daudet_para_9.csv\n",
      "dumas2hugo_para_1.csv\n",
      "dumas2hugo_para_2.csv\n",
      "dumas2hugo_para_3.csv\n",
      "dumas2hugo_para_4.csv\n",
      "dumas2hugo_para_5.csv\n",
      "dumas2hugo_para_6.csv\n",
      "dumas2hugo_para_7.csv\n",
      "dumas_para_1.csv\n",
      "dumas_para_2.csv\n",
      "dumas_para_3.csv\n",
      "dumas_para_4.csv\n",
      "dumas_para_5.csv\n",
      "dumas_para_6.csv\n",
      "dumas_para_7.csv\n",
      "maupassant2hugo_para_21.csv\n",
      "maupassant2hugo_para_22.csv\n",
      "maupassant2hugo_para_23.csv\n",
      "maupassant2hugo_para_24.csv\n",
      "maupassant2hugo_para_25.csv\n",
      "maupassant2hugo_para_26.csv\n",
      "maupassant_para_21.csv\n",
      "maupassant_para_22.csv\n",
      "maupassant_para_23.csv\n",
      "maupassant_para_24.csv\n",
      "maupassant_para_25.csv\n",
      "maupassant_para_26.csv\n",
      "verne2hugo_para_33.csv\n",
      "verne2hugo_para_34.csv\n",
      "verne2hugo_para_35.csv\n",
      "verne2hugo_para_36.csv\n",
      "verne2hugo_para_37.csv\n",
      "verne2hugo_para_38.csv\n",
      "verne2hugo_para_39.csv\n",
      "verne_para_33.csv\n",
      "verne_para_34.csv\n",
      "verne_para_35.csv\n",
      "verne_para_36.csv\n",
      "verne_para_37.csv\n",
      "verne_para_38.csv\n",
      "verne_para_39.csv\n",
      "zola2hugo_para_14.csv\n",
      "zola2hugo_para_15.csv\n",
      "zola2hugo_para_16.csv\n",
      "zola2hugo_para_17.csv\n",
      "zola2hugo_para_18.csv\n",
      "zola2hugo_para_19.csv\n",
      "zola2hugo_para_20.csv\n",
      "zola_para_14.csv\n",
      "zola_para_15.csv\n",
      "zola_para_16.csv\n",
      "zola_para_17.csv\n",
      "zola_para_18.csv\n"
     ]
    }
   ],
   "source": [
    "path_o2h = PKG_DATA_PATH.joinpath(\"others2hugo/tokens\")\n",
    "files_o2h = [f for f in os.listdir(path_o2h) if os.path.isfile(os.path.join(path_o2h, f))]\n",
    "\n",
    "# Print the list of files\n",
    "print(\"Files in the directory:\")\n",
    "for file in files_o2h:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>morph</th>\n",
       "      <th>dep</th>\n",
       "      <th>n_lefts</th>\n",
       "      <th>n_rights</th>\n",
       "      <th>is_sent_start</th>\n",
       "      <th>motif</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ainsi</td>\n",
       "      <td>ainsi</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>ainsi</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chéri</td>\n",
       "      <td>Chéri</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connut</td>\n",
       "      <td>connaître</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>VPS</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dès</td>\n",
       "      <td>dès</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>dès</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13843</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>de</td>\n",
       "      <td>3</td>\n",
       "      <td>zola_para_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13844</th>\n",
       "      <td>toiles</td>\n",
       "      <td>toile</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Gender=Fem|Number=Plur</td>\n",
       "      <td>nmod</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>3</td>\n",
       "      <td>zola_para_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13845</th>\n",
       "      <td>jetées</td>\n",
       "      <td>jeter</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Gender=Fem|Number=Plur|Tense=Past|VerbForm=Part</td>\n",
       "      <td>acl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PPAS</td>\n",
       "      <td>3</td>\n",
       "      <td>zola_para_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13846</th>\n",
       "      <td>pêle-mêle</td>\n",
       "      <td>pêle-mêl</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Gender=Fem|Number=Sing</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>3</td>\n",
       "      <td>zola_para_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13847</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "      <td>zola_para_18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13848 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            text      lemma    pos  \\\n",
       "0          Ainsi      ainsi    ADV   \n",
       "1              ,          ,  PUNCT   \n",
       "2          Chéri      Chéri  PROPN   \n",
       "3         connut  connaître   VERB   \n",
       "4            dès        dès    ADP   \n",
       "...          ...        ...    ...   \n",
       "13843         de         de    ADP   \n",
       "13844     toiles      toile   NOUN   \n",
       "13845     jetées      jeter   VERB   \n",
       "13846  pêle-mêle   pêle-mêl   NOUN   \n",
       "13847          .          .  PUNCT   \n",
       "\n",
       "                                                   morph     dep  n_lefts  \\\n",
       "0                                                    NaN  advmod        0   \n",
       "1                                                    NaN   punct        0   \n",
       "2                                                    NaN   nsubj        0   \n",
       "3      Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...    ROOT        2   \n",
       "4                                                    NaN    case        0   \n",
       "...                                                  ...     ...      ...   \n",
       "13843                                                NaN    case        0   \n",
       "13844                             Gender=Fem|Number=Plur    nmod        1   \n",
       "13845    Gender=Fem|Number=Plur|Tense=Past|VerbForm=Part     acl        0   \n",
       "13846                             Gender=Fem|Number=Sing   xcomp        0   \n",
       "13847                                                NaN   punct        0   \n",
       "\n",
       "       n_rights  is_sent_start  motif  sent_id                   doc  \n",
       "0             1           True  ainsi        0  colette2hugo_para_27  \n",
       "1             0          False      ,        0  colette2hugo_para_27  \n",
       "2             0          False  PROPN        0  colette2hugo_para_27  \n",
       "3             3          False    VPS        0  colette2hugo_para_27  \n",
       "4             0          False    dès        0  colette2hugo_para_27  \n",
       "...         ...            ...    ...      ...                   ...  \n",
       "13843         0          False     de        3          zola_para_18  \n",
       "13844         1          False     NC        3          zola_para_18  \n",
       "13845         1          False   PPAS        3          zola_para_18  \n",
       "13846         0          False     NC        3          zola_para_18  \n",
       "13847         0          False      .        3          zola_para_18  \n",
       "\n",
       "[13848 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in files_o2h:\n",
    "    s = str(path_o2h) + '\\\\' + file\n",
    "    df = pd.read_csv(s)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data_a = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "data_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>morph</th>\n",
       "      <th>dep</th>\n",
       "      <th>n_lefts</th>\n",
       "      <th>n_rights</th>\n",
       "      <th>is_sent_start</th>\n",
       "      <th>motif</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ainsi</td>\n",
       "      <td>ainsi</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>advmod</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>ainsi</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "      <td>colette2hugo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>punct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "      <td>colette2hugo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chéri</td>\n",
       "      <td>Chéri</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "      <td>colette2hugo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connut</td>\n",
       "      <td>connaître</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>VPS</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "      <td>colette2hugo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dès</td>\n",
       "      <td>dès</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>dès</td>\n",
       "      <td>0</td>\n",
       "      <td>colette2hugo_para_27</td>\n",
       "      <td>colette2hugo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text      lemma    pos  \\\n",
       "0   Ainsi      ainsi    ADV   \n",
       "1       ,          ,  PUNCT   \n",
       "2   Chéri      Chéri  PROPN   \n",
       "3  connut  connaître   VERB   \n",
       "4     dès        dès    ADP   \n",
       "\n",
       "                                               morph     dep  n_lefts  \\\n",
       "0                                                NaN  advmod        0   \n",
       "1                                                NaN   punct        0   \n",
       "2                                                NaN   nsubj        0   \n",
       "3  Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...    ROOT        2   \n",
       "4                                                NaN    case        0   \n",
       "\n",
       "   n_rights  is_sent_start  motif  sent_id                   doc        author  \n",
       "0         1           True  ainsi        0  colette2hugo_para_27  colette2hugo  \n",
       "1         0          False      ,        0  colette2hugo_para_27  colette2hugo  \n",
       "2         0          False  PROPN        0  colette2hugo_para_27  colette2hugo  \n",
       "3         3          False    VPS        0  colette2hugo_para_27  colette2hugo  \n",
       "4         0          False    dès        0  colette2hugo_para_27  colette2hugo  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a['author'] = data_a['doc'].str.split('_para').str[0]\n",
    "data_a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Mover's Distance: 0.09958496652441781\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "\n",
    "def emd_score_from_motifs(data1: pd.DataFrame, data2: pd.DataFrame, group_col: str, motif_col: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Earth Mover's Distance (EMD) between the motif distributions\n",
    "    of two datasets grouped by a common identifier.\n",
    "\n",
    "    :param data1: First dataset as a DataFrame.\n",
    "    :param data2: Second dataset as a DataFrame.\n",
    "    :param group_col: Column name to group by (e.g., 'doc').\n",
    "    :param motif_col: Column name containing motifs (e.g., 'motif').\n",
    "    :return: EMD score (approximate).\n",
    "    \"\"\"\n",
    "    # Combine motifs into single \"documents\" grouped by the group column\n",
    "    references = data1.groupby(group_col)[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    hypotheses = data2.groupby(group_col)[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "    # Vectorize motifs using TF-IDF to create multidimensional embeddings\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    ref_vectors = vectorizer.fit_transform(references).toarray()\n",
    "    hyp_vectors = vectorizer.transform(hypotheses).toarray()\n",
    "\n",
    "    # Compute the pairwise Euclidean distance matrix between distributions\n",
    "    distance_matrix = pairwise_distances(ref_vectors, hyp_vectors, metric='euclidean')\n",
    "\n",
    "    # Use the linear sum assignment to find the minimum cost matching\n",
    "    row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "    # Calculate EMD as the average minimum cost based on optimal assignment\n",
    "    emd_distance = distance_matrix[row_ind, col_ind].sum() / len(row_ind)\n",
    "\n",
    "    return emd_distance\n",
    "\n",
    "# Example usage\n",
    "emd_distance = emd_score_from_motifs(data_a[data_a['author'] == \"zola\"], data_a[data_a['author'] == \"zola2hugo\"], group_col=\"author\", motif_col=\"motif\")\n",
    "print(f\"Earth Mover's Distance: {emd_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "colette            PROPN VPS ADV ADJ le NCABS de un NC PPAS . il ...\n",
       "colette2hugo       ainsi , PROPN VPS dès son NUM NC ADJ le NCABS ...\n",
       "daudet             mais ce être ADJ le NC ainsi . le NC PPAS de l...\n",
       "daudet2hugo        mais ainsi PRES le NC ADJ , ADJ , qui chaque N...\n",
       "dumas              cependant , tout PPAS que il se VIMP , il PRES...\n",
       "dumas2hugo         cependant , tout PPAS que il être en ce ADJ NC...\n",
       "maupassant         PPAS dans son NC entre le NC ADJ , il VIMP . c...\n",
       "maupassant2hugo    PPAS dans son NC , il VIMP . un ADJ NC avoir A...\n",
       "verne              quoique il en être , on ne VIMP encore se INF ...\n",
       "verne2hugo         bien que le NC ADJ de le NC être ADJ , son NC ...\n",
       "zola               PROPN , qui VIMP ADJ sur le NC , avoir un NC A...\n",
       "zola2hugo          PROPN , PPAS de plus en plus PPAS dans le mili...\n",
       "Name: motif, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a.groupby('author')['motif'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMD Hugo vs Neutral Hugo vs Restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Mover's Distance Hugo vs Neutral: 0.0880063559708214\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "\n",
    "def emd_score_from_motifs(data1: pd.DataFrame, data2: pd.DataFrame, group_col: str, motif_col: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Earth Mover's Distance (EMD) between the motif distributions\n",
    "    of two datasets grouped by a common identifier.\n",
    "\n",
    "    :param data1: First dataset as a DataFrame.\n",
    "    :param data2: Second dataset as a DataFrame.\n",
    "    :param group_col: Column name to group by (e.g., 'doc').\n",
    "    :param motif_col: Column name containing motifs (e.g., 'motif').\n",
    "    :return: EMD score (approximate).\n",
    "    \"\"\"\n",
    "    # Combine motifs into single \"documents\" grouped by the group column\n",
    "    references = data1.groupby(group_col)[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    hypotheses = data2.groupby(group_col)[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # references = data1[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # hypotheses = data2[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "    # Vectorize motifs using TF-IDF to create multidimensional embeddings\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    ref_vectors = vectorizer.fit_transform(references).toarray()\n",
    "    hyp_vectors = vectorizer.transform(hypotheses).toarray()\n",
    "\n",
    "    # Compute the pairwise Euclidean distance matrix between distributions\n",
    "    distance_matrix = pairwise_distances(ref_vectors, hyp_vectors, metric='euclidean')\n",
    "\n",
    "    # Use the linear sum assignment to find the minimum cost matching\n",
    "    row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "    # Calculate EMD as the average minimum cost based on optimal assignment\n",
    "    emd_distance = distance_matrix[row_ind, col_ind].sum() / len(row_ind)\n",
    "\n",
    "    return emd_distance\n",
    "\n",
    "# Example usage\n",
    "emd_distance_hVhn = emd_score_from_motifs(data_hnh[data_hnh['author'] == \"hugo\"], data_hnh[data_hnh['author'] == \"hugo2neutral\"], group_col=\"author\", motif_col=\"motif\")\n",
    "print(f\"Earth Mover's Distance Hugo vs Neutral: {emd_distance_hVhn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Mover's Distance Hugo vs Restored: 0.13985570588251903\n"
     ]
    }
   ],
   "source": [
    "emd_distance_hVnh = emd_score_from_motifs(data_hnh[data_hnh['author'] == \"hugo\"], data_hnh[data_hnh['author'] == \"neutral2hugo\"], group_col=\"author\", motif_col=\"motif\")\n",
    "print(f\"Earth Mover's Distance Hugo vs Restored: {emd_distance_hVnh}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMD Others vs Other2Hugo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "\n",
    "def emd_score_from_motifs(data1: pd.DataFrame, data2: pd.DataFrame, group_col: str, motif_col: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Earth Mover's Distance (EMD) between the motif distributions\n",
    "    of two datasets grouped by a common identifier.\n",
    "\n",
    "    :param data1: First dataset as a DataFrame.\n",
    "    :param data2: Second dataset as a DataFrame.\n",
    "    :param group_col: Column name to group by (e.g., 'doc').\n",
    "    :param motif_col: Column name containing motifs (e.g., 'motif').\n",
    "    :return: EMD score (approximate).\n",
    "    \"\"\"\n",
    "    # Combine motifs into single \"documents\" grouped by the group column\n",
    "    references = data1.groupby(group_col)[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    hypotheses = data2.groupby(group_col)[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # references = data1[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # hypotheses = data2[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "    # Vectorize motifs using TF-IDF to create multidimensional embeddings\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    ref_vectors = vectorizer.fit_transform(references).toarray()\n",
    "    hyp_vectors = vectorizer.transform(hypotheses).toarray()\n",
    "\n",
    "    # Compute the pairwise Euclidean distance matrix between distributions\n",
    "    distance_matrix = pairwise_distances(ref_vectors, hyp_vectors, metric='euclidean')\n",
    "\n",
    "    # Use the linear sum assignment to find the minimum cost matching\n",
    "    row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "    # Calculate EMD as the average minimum cost based on optimal assignment\n",
    "    emd_distance = distance_matrix[row_ind, col_ind].sum() / len(row_ind)\n",
    "\n",
    "    return emd_distance\n",
    "\n",
    "# Example usage\n",
    "# emd_distance = emd_score_from_motifs(data_a[data_a['author'] == \"zola\"], data_a[data_a['author'] == \"zola2hugo\"], group_col=\"author\", motif_col=\"motif\")\n",
    "# print(f\"Earth Mover's Distance: {emd_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Pair  EMD Score\n",
      "0        colette vs colette2hugo   0.175011\n",
      "1          daudet vs daudet2hugo   0.173188\n",
      "2            dumas vs dumas2hugo   0.184687\n",
      "3  maupassant vs maupassant2hugo   0.139839\n",
      "4            verne vs verne2hugo   0.115854\n",
      "5              zola vs zola2hugo   0.099585\n"
     ]
    }
   ],
   "source": [
    "def compute_emd_table(data: pd.DataFrame, author_col: str, motif_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute EMD distances for all pairs `{name}` and `{name}2hugo` in the author column.\n",
    "    \n",
    "    :param data: Input DataFrame containing authors and motifs.\n",
    "    :param author_col: Column name for authors.\n",
    "    :param motif_col: Column name for motifs.\n",
    "    :return: DataFrame with pairs and their corresponding EMD scores.\n",
    "    \"\"\"\n",
    "    # Extract unique base names for pairs\n",
    "    base_names = ['colette', 'daudet', 'dumas', 'maupassant', 'verne', 'zola']\n",
    "    \n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over base names and compute EMD for each pair\n",
    "    for base_name in base_names:\n",
    "        author1 = base_name\n",
    "        author2 = f\"{base_name}2hugo\"\n",
    "        \n",
    "        if author1 in data[author_col].values and author2 in data[author_col].values:\n",
    "            # Filter data for the two authors\n",
    "            data1 = data[data[author_col] == author1]\n",
    "            data2 = data[data[author_col] == author2]\n",
    "            \n",
    "            # Compute EMD\n",
    "            emd_score = emd_score_from_motifs(data1, data2, group_col=author_col, motif_col=motif_col)\n",
    "            \n",
    "            # Append result\n",
    "            results.append({'Pair': f\"{author1} vs {author2}\", 'EMD Score': emd_score})\n",
    "    \n",
    "    # Create a DataFrame from results\n",
    "    emd_table = pd.DataFrame(results)\n",
    "    return emd_table\n",
    "\n",
    "# Example usage\n",
    "emd_table = compute_emd_table(data_a, author_col=\"author\", motif_col=\"motif\")\n",
    "print(emd_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Pair  EMD Score\n",
      "0     Hugo vs colette   0.199654\n",
      "1      Hugo vs daudet   0.169967\n",
      "2       Hugo vs dumas   0.178175\n",
      "3  Hugo vs maupassant   0.208862\n",
      "4       Hugo vs verne   0.168215\n",
      "5        Hugo vs zola   0.188561\n"
     ]
    }
   ],
   "source": [
    "def emd_score_from_motifs_2(data1: pd.DataFrame, data2: pd.DataFrame, group_col: str, motif_col: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Earth Mover's Distance (EMD) between the motif distributions\n",
    "    of two datasets grouped by a common identifier.\n",
    "\n",
    "    :param data1: First dataset as a DataFrame.\n",
    "    :param data2: Second dataset as a DataFrame.\n",
    "    :param group_col: Column name to group by (e.g., 'doc').\n",
    "    :param motif_col: Column name containing motifs (e.g., 'motif').\n",
    "    :return: EMD score (approximate).\n",
    "    \"\"\"\n",
    "    # Combine motifs into single \"documents\" grouped by the group column\n",
    "    references = data1.groupby(\"doc\")[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    hypotheses = data2.groupby(\"author\")[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # references = data1[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # hypotheses = data2[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "    # Vectorize motifs using TF-IDF to create multidimensional embeddings\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    ref_vectors = vectorizer.fit_transform(references).toarray()\n",
    "    hyp_vectors = vectorizer.transform(hypotheses).toarray()\n",
    "\n",
    "    # Compute the pairwise Euclidean distance matrix between distributions\n",
    "    distance_matrix = pairwise_distances(ref_vectors, hyp_vectors, metric='euclidean')\n",
    "\n",
    "    # Use the linear sum assignment to find the minimum cost matching\n",
    "    row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "    # Calculate EMD as the average minimum cost based on optimal assignment\n",
    "    emd_distance = distance_matrix[row_ind, col_ind].sum() / len(row_ind)\n",
    "\n",
    "    return emd_distance\n",
    "\n",
    "\n",
    "def compute_emd_table_Hugo(data: pd.DataFrame, data_2: pd.DataFrame, motif_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute EMD distances for all pairs `{name}` and `{name}2hugo` in the author column.\n",
    "    \n",
    "    :param data: Input DataFrame containing authors and motifs.\n",
    "    :param author_col: Column name for authors.\n",
    "    :param motif_col: Column name for motifs.\n",
    "    :return: DataFrame with pairs and their corresponding EMD scores.\n",
    "    \"\"\"\n",
    "    # Extract unique base names for pairs\n",
    "    base_names = ['colette', 'daudet', 'dumas', 'maupassant', 'verne', 'zola']\n",
    "    \n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over base names and compute EMD for each pair\n",
    "    for base_name in base_names:\n",
    "        author1 = base_name\n",
    "        author2 = \"Hugo\"\n",
    "        \n",
    "        if author1 in data['author'].values:\n",
    "            # Filter data for the two authors\n",
    "            data1 = data[data['author'] == author1]\n",
    "            data2 = hugo_para\n",
    "            \n",
    "            # Compute EMD\n",
    "            emd_score = emd_score_from_motifs_2(data2, data1, group_col='author', motif_col=motif_col)\n",
    "            \n",
    "            # Append result\n",
    "            results.append({'Pair': f\"{author2} vs {author1}\", 'EMD Score': emd_score})\n",
    "    \n",
    "    # Create a DataFrame from results\n",
    "    emd_table = pd.DataFrame(results)\n",
    "    return emd_table\n",
    "\n",
    "# Example usage\n",
    "emd_table_hVo = compute_emd_table_Hugo(data_a, hugo_para, motif_col=\"motif\")\n",
    "print(emd_table_hVo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Pair  EMD Score\n",
      "0     Hugo vs colette2hugo   0.225814\n",
      "1      Hugo vs daudet2hugo   0.252923\n",
      "2       Hugo vs dumas2hugo   0.193353\n",
      "3  Hugo vs maupassant2hugo   0.242771\n",
      "4       Hugo vs verne2hugo   0.157094\n",
      "5        Hugo vs zola2hugo   0.170316\n"
     ]
    }
   ],
   "source": [
    "def emd_score_from_motifs_2(data1: pd.DataFrame, data2: pd.DataFrame, group_col: str, motif_col: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Earth Mover's Distance (EMD) between the motif distributions\n",
    "    of two datasets grouped by a common identifier.\n",
    "\n",
    "    :param data1: First dataset as a DataFrame.\n",
    "    :param data2: Second dataset as a DataFrame.\n",
    "    :param group_col: Column name to group by (e.g., 'doc').\n",
    "    :param motif_col: Column name containing motifs (e.g., 'motif').\n",
    "    :return: EMD score (approximate).\n",
    "    \"\"\"\n",
    "    # Combine motifs into single \"documents\" grouped by the group column\n",
    "    references = data1.groupby(\"doc\")[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    hypotheses = data2.groupby(\"author\")[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # references = data1[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "    # hypotheses = data2[motif_col].apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "    # Vectorize motifs using TF-IDF to create multidimensional embeddings\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    ref_vectors = vectorizer.fit_transform(references).toarray()\n",
    "    hyp_vectors = vectorizer.transform(hypotheses).toarray()\n",
    "\n",
    "    # Compute the pairwise Euclidean distance matrix between distributions\n",
    "    distance_matrix = pairwise_distances(ref_vectors, hyp_vectors, metric='euclidean')\n",
    "\n",
    "    # Use the linear sum assignment to find the minimum cost matching\n",
    "    row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "    # Calculate EMD as the average minimum cost based on optimal assignment\n",
    "    emd_distance = distance_matrix[row_ind, col_ind].sum() / len(row_ind)\n",
    "\n",
    "    return emd_distance\n",
    "\n",
    "\n",
    "def compute_emd_table_Hugo(data: pd.DataFrame, data_2: pd.DataFrame, motif_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute EMD distances for all pairs `{name}` and `{name}2hugo` in the author column.\n",
    "    \n",
    "    :param data: Input DataFrame containing authors and motifs.\n",
    "    :param author_col: Column name for authors.\n",
    "    :param motif_col: Column name for motifs.\n",
    "    :return: DataFrame with pairs and their corresponding EMD scores.\n",
    "    \"\"\"\n",
    "    # Extract unique base names for pairs\n",
    "    base_names = ['colette', 'daudet', 'dumas', 'maupassant', 'verne', 'zola']\n",
    "    \n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over base names and compute EMD for each pair\n",
    "    for base_name in base_names:\n",
    "        author1 = f\"{base_name}2hugo\"\n",
    "        author2 = \"Hugo\"\n",
    "        \n",
    "        if author1 in data['author'].values:\n",
    "            # Filter data for the two authors\n",
    "            data1 = data[data['author'] == author1]\n",
    "            data2 = hugo_para\n",
    "            \n",
    "            # Compute EMD\n",
    "            emd_score = emd_score_from_motifs_2(data2, data1, group_col='author', motif_col=motif_col)\n",
    "            \n",
    "            # Append result\n",
    "            results.append({'Pair': f\"{author2} vs {author1}\", 'EMD Score': emd_score})\n",
    "    \n",
    "    # Create a DataFrame from results\n",
    "    emd_table = pd.DataFrame(results)\n",
    "    return emd_table\n",
    "\n",
    "# Example usage\n",
    "emd_table_hVo2h = compute_emd_table_Hugo(data_a, hugo_para, motif_col=\"motif\")\n",
    "print(emd_table_hVo2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>EMD Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hugo vs colette</td>\n",
       "      <td>0.199654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hugo vs daudet</td>\n",
       "      <td>0.169967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hugo vs dumas</td>\n",
       "      <td>0.178175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hugo vs maupassant</td>\n",
       "      <td>0.208862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hugo vs verne</td>\n",
       "      <td>0.168215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hugo vs zola</td>\n",
       "      <td>0.188561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Pair  EMD Score\n",
       "0     Hugo vs colette   0.199654\n",
       "1      Hugo vs daudet   0.169967\n",
       "2       Hugo vs dumas   0.178175\n",
       "3  Hugo vs maupassant   0.208862\n",
       "4       Hugo vs verne   0.168215\n",
       "5        Hugo vs zola   0.188561"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emd_table_hVo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>EMD Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hugo vs colette2hugo</td>\n",
       "      <td>0.225814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hugo vs daudet2hugo</td>\n",
       "      <td>0.252923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hugo vs dumas2hugo</td>\n",
       "      <td>0.193353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hugo vs maupassant2hugo</td>\n",
       "      <td>0.242771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hugo vs verne2hugo</td>\n",
       "      <td>0.157094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hugo vs zola2hugo</td>\n",
       "      <td>0.170316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Pair  EMD Score\n",
       "0     Hugo vs colette2hugo   0.225814\n",
       "1      Hugo vs daudet2hugo   0.252923\n",
       "2       Hugo vs dumas2hugo   0.193353\n",
       "3  Hugo vs maupassant2hugo   0.242771\n",
       "4       Hugo vs verne2hugo   0.157094\n",
       "5        Hugo vs zola2hugo   0.170316"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emd_table_hVo2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20704491768764868"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(emd_table_hVo2h['EMD Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1855724381850007"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(emd_table_hVo['EMD Score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymotifs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
